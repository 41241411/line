import logging
import requests
from bs4 import BeautifulSoup
from ocr_model import ocr_image_from_bytes

def login_and_fetch_scores(student_id, password, mode="latest"):
    session = requests.Session()
    base_url = "https://ecare.nfu.edu.tw"
    captcha_url = base_url + "/ext/authimg"

    retry = 0
    captcha_text = ""
    while retry < 3:
        try:
            captcha_resp = session.get(captcha_url, timeout=5)
            captcha_resp.raise_for_status()
            captcha_text = ocr_image_from_bytes(captcha_resp.content).strip()
            logging.info(f"ðŸ” è¾¨è­˜åˆ°çš„é©—è­‰ç¢¼ï¼š{captcha_text}")
            if len(captcha_text) == 4:
                break
        except requests.exceptions.RequestException as e:
            logging.error(f"âš ï¸ é©—è­‰ç¢¼è«‹æ±‚å¤±æ•—ï¼š{e}")
            return "âŒ ç„¡æ³•é€£ç·šåˆ°é©—è­‰ç¢¼ä¼ºæœå™¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        retry += 1

    if len(captcha_text) != 4:
        return "âŒ é©—è­‰ç¢¼è¾¨è­˜å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

    login_url = base_url + "/login/auth"
    payload = {
        "login_acc": student_id,
        "login_pwd": password,
        "login_chksum": captcha_text,
    }
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": base_url + "/login",
    }

    try:
        res = session.post(login_url, data=payload, headers=headers, allow_redirects=False, timeout=5)
    except requests.exceptions.RequestException as e:
        logging.error(f"âš ï¸ ç™»å…¥è«‹æ±‚å¤±æ•—ï¼š{e}")
        return "âŒ ç„¡æ³•ç™»å…¥ç³»çµ±ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

    if res.status_code != 302:
        return f"âŒ ç™»å…¥å¤±æ•—ï¼Œå¸³è™Ÿæˆ–å¯†ç¢¼å¯èƒ½éŒ¯èª¤ã€‚"

    score_url = base_url + ("/aaiqry/studscore" if mode == "latest" else "/aaiqry/studscore?kind=2")
    try:
        score_resp = session.get(score_url, timeout=5)
        score_resp.raise_for_status()
    except requests.exceptions.RequestException as e:
        logging.error(f"âš ï¸ æˆç¸¾é é¢è«‹æ±‚å¤±æ•—ï¼š{e}")
        return "âŒ ç„¡æ³•å–å¾—æˆç¸¾é é¢ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

    soup = BeautifulSoup(score_resp.text, "html.parser")
    score_section = soup.find('div', id='showmag')
    if not score_section:
        return "âŒ æ‰¾ä¸åˆ°æˆç¸¾å…§å®¹å€å¡Šã€‚"

    table = score_section.find('table', class_='tbcls')
    if not table:
        return "âŒ æ‰¾ä¸åˆ°æˆç¸¾è¡¨æ ¼ã€‚"

    table_rows = table.find_all('tr')
    result = []

    for row in table_rows[1:]:
        columns = row.find_all('td')
        try:
            if mode == "latest":
                if len(columns) < 11:
                    continue
                column_data = {
                    "èª²ç¨‹åç¨±": columns[3].text.strip(),
                    "å­¸åˆ†": columns[5].text.strip(),
                    "æœŸä¸­åˆ†æ•¸": columns[6].text.strip(),
                    "å­¸æœŸåˆ†æ•¸": columns[7].text.strip(),
                    "å­¸æœŸå–®ç§‘ç­æŽ’å": columns[8].text.strip(),
                }
            else:
                if len(columns) < 7:
                    continue
                column_data = {
                    "èª²ç¨‹å­¸å¹´": columns[1].text.strip(),
                    "èª²ç¨‹å­¸æœŸ": columns[2].text.strip(),
                    "èª²ç¨‹åç¨±": columns[3].text.strip(),
                    "å­¸åˆ†": columns[5].text.strip(),
                    "å­¸æœŸåˆ†æ•¸": columns[6].text.strip(),
                }
            result.append(column_data)
        except Exception as e:
            logging.error(f"âš ï¸ è³‡æ–™è§£æžéŒ¯èª¤ï¼š{e}")
            continue

    if not result:
        return "âŒ æŸ¥ç„¡ä»»ä½•æˆç¸¾è³‡æ–™ã€‚"

    return result
